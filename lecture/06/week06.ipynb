{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 06, ASTR 596: Fundamentals of Data Science\n",
    "\n",
    "\n",
    "## Sampling and MCMC\n",
    "\n",
    "### Gautham Narayan \n",
    "##### <gsn@illinois.edu>\n",
    "\n",
    "Borrowing heavily from David Kirkby and Adam Mantz this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> HW4 Tips: </center>\n",
    "\n",
    "### <center> Q1: Read the problem, in particular what I gave you for A. </center>\n",
    "### <center> Q2: Think about $g(x|x')$ and $g(x'|x)$ for stationary kernels that only depend on $\\left|x-x'\\right|$ and where you start, how large a step you take.</center>\n",
    "### <center> Q3: I had you change variables from flux to magnitudes - does the functional form of the model still look the same? </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Markov Chains\n",
    "\n",
    "* We've come up with a model, an objective/loss/likelihood function and some priors\n",
    "* Now we actually want to evaluate the posterior $P(\\theta|D)$\n",
    "    * analytically is too hard, so we draw samples (i.e. **Monte Carlo**) \n",
    "        * convert messy integrals to sums over the samples \n",
    "* Simple Monte Carlo was wasteful because we don't want to draw samples over all parameter space\n",
    "    * one way to make it more efficient was make samples that are correlated with each other\n",
    "        * keep sampling in regions of high probability, don't sample in regions without\n",
    "        * Markov Chains are series of samples where every sample only depends on the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Want to setup the problem so the frequency of samples in some region of width $dx$ **is proportional** to some function of $x$\n",
    "* There are two ways to do this:\n",
    "    * Rejection sampling - general purpose\n",
    "    * Inverse Transform sampling - too restrictive, because functions must be invertible\n",
    "* If we're using rejection sampling to pick samples on our Markov Chain, we're doing **Markov Chain Monte Carlo** with **Metropolis Hastings** as our sampling strategy\n",
    "    * The **equilibrium** state of this chain is the stationary distribution of samples we desire\n",
    "    * If the chain isn't in equilibrium, well **tough luck.** Tune more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "To be useful to us, a chain must\n",
    "1. have converged to the posterior distribution\n",
    "2. provide enough effectively independent samples to characterize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would make us confident of convergence?\n",
    "* Is the chain stationary?\n",
    "* Do independent chains started from overdispersed positions find the same solution?\n",
    "\n",
    "How do we guess the number of independent samples?\n",
    "* Check how well the chain appears to exploring the distribution.\n",
    "* Compare the autocorrelation length scale with the chain length.\n",
    "\n",
    "There are numerical estimates that can help with this, but **they are not a substitute for human visual inspection**.\n",
    "\n",
    "i.e. \n",
    "## <center> Look at your data. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Common misuses of/misconceptions about convergence\n",
    "\n",
    "Convergence does **not** mean\n",
    "* that parameters are \"well constrained\" by the data\n",
    "* that the autocorrelation length is small\n",
    "* that there are not occasional excursions beyond a locus in parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class exercise:\n",
    "\n",
    "We need our chains to have two properties:\n",
    "Which of these chains are a) reversible b) stationary\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"chains.jpg\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* How stationary does each sequence appear? \n",
    "* Are all chains sampling the same PDF? Compare to what you found for `pgauss` on HW4\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_sandbox_ab.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence tests\n",
    "* Look at your data! There is no substitute.\n",
    "* Gelman-Rubin statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_sandbox_a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_sandbox_b.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Burnin\n",
    "\n",
    "Conservatively, we might remove the first $\\sim500$ steps based on this. This period is called the **burn in**.\n",
    "\n",
    "# Gelman-Rubin convergence statistic\n",
    "\n",
    "This approach tests the similarlity of independent chains intended to sample the same PDF. To be meaningful, **they should start from different locations and burn-in should be removed.**\n",
    "\n",
    "For a given parameter, $\\theta$, the $R$ statistic compares the variance across chains with the variance within a chain. Intuitively, if the chains are random-walking in very different places, i.e. not sampling the same distribution, $R$ will be large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In detail, given chains $J=1,\\ldots,m$, each of length $n$,\n",
    "\n",
    "\n",
    "## $$B=\\frac{n}{m-1} \\sum_j \\left(\\bar{\\theta}_j - \\bar{\\theta}\\right)^2$$\n",
    "\n",
    "where $\\bar{\\theta_j}$ is the average $\\theta$ for chain $j$ and $\\bar{\\theta}$ is the global average. This is proportional to the variance of the individual-chain averages for $\\theta$.\n",
    "\n",
    "\n",
    "## $$W=\\frac{1}{m}\\sum_j s_j^2$$\n",
    "\n",
    "where $s_j^2$ is the estimated variance of $\\theta$ within chain $j$. \n",
    "This is the average of the individual-chain variances for $\\theta$.\n",
    "\n",
    "## $$V=\\frac{n-1}{n}W + \\frac{1}{n}B$$\n",
    "This is an estimate for the overall variance of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, \n",
    "\n",
    "## $$R=\\sqrt{\\frac{V}{W}}$$\n",
    "\n",
    "We'd like to see $R\\approx 1$ (e.g. $R<1.1$ is often used).\n",
    "\n",
    "Note that this calculation can also be used to track convergence of combinations of parameters, or anything else derived from them.\n",
    "\n",
    "Iff $R\\approx 1$, then the chains are described as **well mixed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We also gave up a nice property of Simple Monte Carlo moving to Markov Chain Monte Carlo. Our samples are now correlated - i.e. you literally took a position and adjusted it by a small amount. This means that when you request 10,000 samples from Metropolis Hastings, you aren't actually getting 10,000 samples because they aren't **independent**.\n",
    "\n",
    "### Correlation tests\n",
    "* Look at your data! Again, no substitute.\n",
    "* Autocorrelation of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Do subsequent samples look particularly independent?\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_sandbox_a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The **autocorrelation** of a sequence (**after** removing burn-in), as a function of lag, $k$, is:\n",
    "\n",
    "## $$\\rho_k = \\frac{\\sum_{i=1}^{n-k}\\left(\\theta_{i} - \\bar{\\theta}\\right)\\left(\\theta_{i+k} - \\bar{\\theta}\\right)}{\\sum_{i=1}^{n-k}\\left(\\theta_{i} - \\bar{\\theta}\\right)^2} = \\frac{\\mathrm{Cov}_i\\left(\\theta_i,\\theta_{i+k}\\right)}{\\mathrm{Var}(\\theta)}$$\n",
    "\n",
    "The larger lag one needs to get a small autocorrelation, the less informative individual samples are.\n",
    "\n",
    "The `pandas` function `autocorrelation_plot()` may be useful for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><<img src=\"mc1_sandbox_acf-a.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_sandbox_acf-b.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the positive/negative oscillations basically tell us when the lag is so large compared with the chain length that the autocorrelation is too noisy to be meaningful.\n",
    "\n",
    "We would be justified in **thinning** the chains by a factor of âˆ¼150, apparently! (i.e. take every 150th sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Effective number of samples\n",
    "\n",
    "From $m$ chains of length $n$, we can estimate the effective number of independent samples as\n",
    "\n",
    "## $$n_{eff} = \\frac{mn}{1+2\\sum_0^\\infty \\hat{\\rho}_t}$$\n",
    "\n",
    "with\n",
    "\n",
    "## $$\\hat{\\rho}_t = 1 - \\frac{V_t}{2V}$$\n",
    "\n",
    "($V$ in the denominator as in the Gelman-Rubin calculation)\n",
    "\n",
    "## $$V_t = \\frac{1}{m(n-t)} \\sum_{j=0}^m \\sum_{i=t+1}^n (\\theta_{i,j} - \\theta_{i-t,j})^2$$\n",
    "\n",
    "In practice, the sum in $n_{eff}$ is cut off when the estimates $\\hat{\\rho}_t$ become too noisy (see references)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In class exercise: can we declare victory?\n",
    "\n",
    "In each of the following trace plots, different colors show independent chains. For each decide by inspection whether the following are plausible claims:\n",
    "1. The chains have converged to the posterior.\n",
    "2. The chains have a reasonable number of independent samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_convgame_1.png\" width=100%></td>\n",
    "        <td><img src=\"mc1_convgame_2.png\" width=100%></td>\n",
    "    </tr><tr>\n",
    "        <td><img src=\"mc1_convgame_3.png\" width=100%></td>\n",
    "        <td><img src=\"mc1_convgame_4.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tuning is a kind of boring and painful. And if we're going to start multiple chains anyway, might as well start them all at once.\n",
    "\n",
    "## Affine-invariant MC (i.e. `emcee`)\n",
    "\n",
    "* Based on the paper by [Goodman and Weare](https://msp.org/camcos/2010/5-1/p04.xhtml)\n",
    "\n",
    "* implemented in `emcee`\n",
    "\n",
    "* many walkers simultaneously generating correlated Markov Chains\n",
    "\n",
    "* **Affine Invariance** - efficiency not impacted by any linear (aka affine) transformation of the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is one of a class of methods that evolve an *ensemble* of states rather than a single state.\n",
    "After convergence, the ensemble can be regarded as a set of samples from the target distribution.\n",
    "\n",
    "This approach provides some of the benefits of running multiple chains - but remember that these are not *independent* chains!\n",
    "\n",
    "### The Goodman-Weare method\n",
    "\n",
    "The algorithm for moving each point in the ensemble is:\n",
    "1. Randomly pick a different point from the ensemble (total size $N$).\n",
    "2. Propose a move in the direction of that point, by the distance between them multiplied by a random from this distribution:\n",
    "$g(z) \\propto \\frac{1}{\\sqrt z}; ~ \\frac{1}{2}\\leq z \\leq 2$\n",
    "3. Accept or reject the move based on the ratio of posterior densities multiplied by $z^{N-1}$.\n",
    "\n",
    "Note that there is some magic in the density $g$. We are not free to choose just any function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This algorithm is relatively easy to use - there is no tuning required and it's straightforward to parallelize.\n",
    "\n",
    "Important cautions:\n",
    "* if the ensemble is not started in a region of high probability, convergence will be **extremely** slow. Y\n",
    "* as the walkers are not independent, the Gelman-Rubin convergence criterion doesn't apply\n",
    "* assessing convergence visually is not always straightforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class exercise - Using `emcee` to deal with the HW2 problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "from scipy import optimize\n",
    "\n",
    "# this just makes plots a bit easier on my laptop - disable as needed\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "\n",
    "\n",
    "x = np.array([ 0,  3,  9, 14, 15, 19, 20, 21, 30, 35,\n",
    "              40, 41, 42, 43, 54, 56, 67, 69, 72, 88])\n",
    "y = np.array([33, 68, 34, 34, 37, 71, 37, 44, 48, 49,\n",
    "              53, 49, 50, 48, 56, 60, 61, 63, 44, 71])\n",
    "e = np.array([ 3.6, 3.9, 2.6, 3.4, 3.8, 3.8, 2.2, 2.1, 2.3, 3.8,\n",
    "               2.2, 2.8, 3.9, 3.1, 3.4, 2.6, 3.4, 3.7, 2.0, 3.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def squared_loss(theta, x=x, y=y, e=e):\n",
    "    dy = y - theta[0] - theta[1] * x\n",
    "    return np.sum(0.5 * (dy / e) ** 2)\n",
    "\n",
    "theta1 = optimize.fmin(squared_loss, [0, 0], disp=False)\n",
    "\n",
    "xfit = np.linspace(0, 100)\n",
    "plt.errorbar(x, y, e, fmt='.k', ecolor='gray')\n",
    "plt.plot(xfit, theta1[0] + theta1[1] * xfit, '-k')\n",
    "plt.title('Maximum Likelihood fit: Squared Loss');\n",
    "\n",
    "def huber_loss(t, c=3):\n",
    "    return ((abs(t) < c) * 0.5 * t ** 2\n",
    "            + (abs(t) >= c) * -c * (0.5 * c - abs(t)))\n",
    "\n",
    "\n",
    "def total_huber_loss(theta, x=x, y=y, e=e, c=3):\n",
    "    return huber_loss((y - theta[0] - theta[1] * x) / e, c).sum()\n",
    "\n",
    "theta2 = optimize.fmin(total_huber_loss, [0, 0], disp=False)\n",
    "\n",
    "plt.errorbar(x, y, e, fmt='.k', ecolor='gray')\n",
    "plt.plot(xfit, theta1[0] + theta1[1] * xfit, color='lightgray')\n",
    "plt.plot(xfit, theta2[0] + theta2[1] * xfit, color='black')\n",
    "plt.title('Maximum Likelihood fit: Huber loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Bayesian approach to accounting for outliers generally involves *modifying the model* so that the outliers are accounted for. For this data, it is abundantly clear that a simple straight line is not a good fit to our data. So let's propose a more complicated model that has the flexibility to account for outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One option is to choose a mixture between a signal and a background:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "p(\\{x_i\\}, \\{y_i\\},\\{e_i\\}~|~\\theta,\\{g_i\\},\\sigma,\\sigma_b) = & \\frac{g_i}{\\sqrt{2\\pi e_i^2}}\\exp\\left[\\frac{-\\left(\\hat{y}(x_i~|~\\theta) - y_i\\right)^2}{2e_i^2}\\right] \\\\\n",
    "&+ \\frac{1 - g_i}{\\sqrt{2\\pi \\sigma_B^2}}\\exp\\left[\\frac{-\\left(\\hat{y}(x_i~|~\\theta) - y_i\\right)^2}{2\\sigma_B^2}\\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "What we've done is expanded our model with some nuisance parameters: $\\{g_i\\}$ is a series of weights which range from 0 to 1 and encode for each point $i$ the degree to which it fits the model. $g_i=0$ indicates an outlier, in which case a Gaussian of width $\\sigma_B$ is used in the computation of the likelihood. This $\\sigma_B$ can also be a nuisance parameter, or its value can be set at a sufficiently high number, say 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our model is much more complicated now: it has 22 parameters rather than 2, but the majority of these can be considered nuisance parameters, which can be marginalized-out in the end, just as we marginalized (integrated) over $p$ in the Billiard example.  Let's construct a function which implements this likelihood. As in the previous post, we'll use the [emcee](http://dan.iel.fm/emcee/current/) package to explore the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To actually compute this, we'll start by:\n",
    "* defining the model (done implicitly)\n",
    "* functions describing our likelihood function\n",
    "* our prior\n",
    "* and posterior\n",
    "\n",
    "And then you get to use emcee to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    #g_i needs to be between 0 and 1\n",
    "    if (all(theta[2:] > 0) and all(theta[2:] < 1)):\n",
    "        return 0\n",
    "    else:\n",
    "        return -np.inf  # recall log(0) = -inf\n",
    "\n",
    "def log_likelihood(theta, x, y, e, sigma_B):\n",
    "    dy = y - theta[0] - theta[1] * x\n",
    "    g = np.clip(theta[2:], 0, 1)  # g<0 or g>1 leads to NaNs in logarithm\n",
    "    logL1 = np.log(g) - 0.5 * np.log(2 * np.pi * e ** 2) - 0.5 * (dy / e) ** 2\n",
    "    logL2 = np.log(1 - g) - 0.5 * np.log(2 * np.pi * sigma_B ** 2) - 0.5 * (dy / sigma_B) ** 2\n",
    "    return np.sum(np.logaddexp(logL1, logL2))\n",
    "\n",
    "def log_posterior(theta, x, y, e, sigma_B):\n",
    "    return log_prior(theta) + log_likelihood(theta, x, y, e, sigma_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that this step will take a few minutes to run!\n",
    "\n",
    "ndim = 2 + len(x)  # number of parameters in the model\n",
    "nwalkers = 50  # number of MCMC walkers\n",
    "nburn = 10000  # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 15000  # number of MCMC steps to take\n",
    "\n",
    "# set theta near the maximum likelihood, with \n",
    "np.random.seed(10)\n",
    "starting_guesses = np.zeros((nwalkers, ndim))\n",
    "starting_guesses[:, :2] = np.random.normal(theta1, 1, (nwalkers, 2))\n",
    "starting_guesses[:, 2:] = np.random.normal(0.5, 0.1, (nwalkers, ndim - 2))\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once we have these samples, we can exploit a very nice property of the Markov chains. Because their distribution models the posterior, we can integrate out (i.e. marginalize) over nuisance parameters simply by ignoring them!\n",
    "\n",
    "We can look at the (marginalized) distribution of slopes and intercepts by examining the first two columns of the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(sample[:, 0], sample[:, 1], ',k', alpha=0.1)\n",
    "plt.xlabel('intercept')\n",
    "plt.ylabel('slope');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We see a distribution of points near a slope of $\\sim 0.45$, and an intercept of $\\sim 31$. We'll plot this model over the data below, but first let's see what other information we can extract from this trace.\n",
    "\n",
    "One nice feature of analyzing MCMC samples is that the choice of nuisance parameters is completely symmetric: just as we can treat the $\\{g_i\\}$ as nuisance parameters, we can also treat the slope and intercept as nuisance parameters! Let's do this, and check the posterior for $g_1$ and $g_2$, the outlier flag for the first two points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(sample[:, 2], sample[:, 3], ',k', alpha=0.1)\n",
    "plt.xlabel('$g_1$')\n",
    "plt.ylabel('$g_2$')\n",
    "\n",
    "print(\"g1 mean: {0:.2f}\".format(sample[:, 2].mean()))\n",
    "print(\"g2 mean: {0:.2f}\".format(sample[:, 3].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is not an extremely strong constraint on either of these, but we do see that $(g_1, g_2) = (1, 0)$ is slightly favored: the means of $g_1$ and $g_2$ are greater than and less than 0.5, respecively. If we choose a cutoff at $g=0.5$, our algorithm has identified $g_2$ as an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's make use of all this information, and plot the marginalized best model over the original data. As a bonus, we'll draw red circles to indicate which points the model detects as outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "theta3 = np.mean(sample[:, :2], 0)\n",
    "g = np.mean(sample[:, 2:], 0)\n",
    "outliers = (g < 0.5)\n",
    "\n",
    "plt.errorbar(x, y, e, fmt='.k', ecolor='gray')\n",
    "plt.plot(xfit, theta1[0] + theta1[1] * xfit, color='lightgray')\n",
    "plt.plot(xfit, theta2[0] + theta2[1] * xfit, color='lightgray')\n",
    "plt.plot(xfit, theta3[0] + theta3[1] * xfit, color='black')\n",
    "plt.plot(x[outliers], y[outliers], 'ro', ms=20, mfc='none', mec='red')\n",
    "plt.title('Maximum Likelihood fit: Bayesian Marginalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* regularization\n",
    "    * bias-variance tradeoff\n",
    "        \n",
    "* gibbs sampling\n",
    "    * conjugate priors -> PIT\n",
    "* PT -> simmulated annealing "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:fds] *",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
