{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR596, FDS: Homework set 2 - Maximum Likelihood\n",
    "\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "###  Fitting a Line using a Maximum Likelihood Estimator\n",
    "\n",
    "Last week, you implcitly fitted straight lines with methods of moments estimators (i.e. sample mean and variance) and L-estimators (median and IQR). Generally though, we want some kind of uncertainty estimate for our models, and therefore M-estimators and maximum likelihood estimators in particular are useful.\n",
    "\n",
    "Assume the scatter in our measurements (the residuals) is generated by a gaussian process. I.e.:\n",
    "\n",
    ">$ y_i = a x_i + b + r_i $\n",
    "\n",
    "where $r_i$ is drawn from $N(0, \\sigma)$. Here, $\\sigma$ is the error the measurement induces.\n",
    "\n",
    "To use an M-estimator/MLE, you have to specify the likelihood function. First, the probability $p(y_i|x_i, M(a, b), \\sigma)$ that a particular point $y_i$ would be measured is just the normal distribution:\n",
    "\n",
    ">$ p(y_i|x_i, M(a, b), \\sigma) = N(y_i - M(x)|\\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(y_i - M(x_i))^2}{2 \\sigma^2} \\right) $.\n",
    "\n",
    "Given what we discussed in class, we can write down the $\\ln L$\n",
    "\n",
    ">$ \\ln L(a, b) = constant - \\frac{1}{2 \\sigma^2} \\sum_{i=1}^N (y_i - M(x_i))^2 $\n",
    "\n",
    "This is the expression that we now minimize with respect to $a$ and $b$ to find ML estimators for those parameters. \n",
    "\n",
    "\n",
    "And as we discussed in class, this is equivalent to minimizing the sum of the squares or a _least-squares method_.\n",
    "\n",
    "## MLE with outliers\n",
    "\n",
    "Let's apply the MLE to data with uncertainties where these uncertainties include outliers. \n",
    "I've defined a dataset below:\n",
    "\n",
    "Your mission is to:\n",
    "\n",
    "- write a function that computes the squared loss, and incorporates the uncertainties on the measurements, $dy$\n",
    "- Fit a line to the full sample by evaluating this likelihood on a grid of a, b\n",
    "- Use sigma-clipping or an L-estimator for outlier rejection and fit a line to the data with outliers rejected\n",
    "- Make a QQ plot of the residuals\n",
    "- Define a new likelihood function that implements the Huber loss, also incorporating the measurement uncertainties $dy$\n",
    "- Fit a new line to all of the data (no outlier rejection) with the new Huber likelihod, except now use scipy.optimize.fmin instead of a grid search.\n",
    "- You know the drill by now - QQ plot of the residuals\n",
    "\n",
    "Recommended reading: David Hogg, Jo Bovy, and Dustin Lang: \"Data analysis recipes: Fitting a model to data\", 2010: https://arxiv.org/abs/1008.4686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.optimize\n",
    "from astroML.datasets import fetch_hogg2010test\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Get data: this includes outliers\n",
    "data = fetch_hogg2010test()\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "dy = data['sigma_y']\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2: Optimal Photometry\n",
    "\n",
    "We now turn to examples of applications of ML in astronomy. \n",
    "\n",
    "We'll look at two cases: simple photometry and simultaneous fitting of galaxy size and total flux.\n",
    "\n",
    "Last week, I had you download a bunch of SDSS data files and plot `MAG_PSF` from them?\n",
    "But what is this quantitiy and where the heck did it come from?\n",
    "\n",
    "Have a look at one of the example images we saw as an example of astronomical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### RUN THIS CELL \n",
    "! ds9 -scale zscale ../../data/01/wdd7.071117_0328.073_6.sw.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A star and a point spread function\n",
    "\n",
    "The stars in those images are not point sources, despite being trillions of kilometers from us. This is because as the light from the stars meet travel to meet their fate on our CCD detectors here on Earth, it gets spread out from a perfect point.\n",
    "\n",
    "The **Point Spread Function** (the \"PSF\") is comprised of various contributions: from minute misalignments in the optics, to jitter in the tracking, to diffraction from the spider, to diffusion of the electrons as they travel through the silicon in the CCD (\"charge diffusion\"), to the homogenization of the PSF due to the refraction and diffraction in the atmosphere.  \n",
    "\n",
    "The dominant effect is the one ***from the atmosphere***.\n",
    "\n",
    "![PSF Formation](figures/psf-formation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we don't construct the PSF from *ab initio* considerations because it's impractical to track each of these effects separately.\n",
    "\n",
    "Instead, we measure it by looking at the observed shape of bright, isolated, point sources (i.e., stars). Those observations are noisy, so we fit analytical profiles to estimate the true PSF.\n",
    "\n",
    "For simplicity, we will use just a single bivariate Gaussian here.\n",
    "\n",
    "This is our model.\n",
    "\n",
    "\n",
    "\n",
    "As before, we'll generate some data - but not for 1000s of sources. Just one. It'll be stored in a variable named `image`\n",
    "You can see the true parameters of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-614af54b3e60>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-614af54b3e60>\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    return psf\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# DO NOT ALTER THIS CODE:\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from astroML.plotting.mcmc import convert_to_stdev\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "def plotCutout(img, title = None, clabel='$counts$', xlabel='x (pixels)', ylabel='y (pixels)', loc=None, fig=None):\n",
    "    \"\"\"Make a nice looking plot of a small image\"\"\"\n",
    "    if loc is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        fig.subplots_adjust(right=0.8, bottom=0.34)\n",
    "    else:\n",
    "        ax = fig.add_subplot(loc)\n",
    "\n",
    "    # coordinate of the edge (assuming a square image)\n",
    "    xe = img.shape[0] / 2.\n",
    "\n",
    "    if title is None:\n",
    "        title = \"min = %.0f, max=%.0f\" % (img.min(), img.max())\n",
    "    \n",
    "    ax.set_title(title, fontsize=14)\n",
    "    plt.imshow(img, origin='lower', interpolation='nearest',\n",
    "           extent=(-xe, xe, -xe, xe),\n",
    "           cmap=plt.cm.binary, aspect=1)\n",
    "    plt.clim(-20, 100)\n",
    "    plt.colorbar().set_label(clabel)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "\n",
    "\n",
    "# These will be the parameters of our image:\n",
    "\n",
    "Atrue = 10000.0    # the source count normalization\n",
    "xdim = 15         # width of the image\n",
    "ydim = 15         # height of the image\n",
    "muXtrue = 0.0     # source x centroid \n",
    "muYtrue = 0.0     # source y centroid \n",
    "sigmaPSF = 1.5    # in pixels, corresponds to seeing = 1.5*0.2*2.355 = 0.7 arcsec for LSST (0.2\" pix)\n",
    "skyBg = 25        # sky background\n",
    "\n",
    "\n",
    "def makePSF(shape, x0, y0, sigmaPSF):\n",
    "    # Add a (Gaussian) PSF of width sigmaPSF, centered on (x0, y0)\n",
    "    xx = np.arange(shape[0]) - shape[0]/2.+0.5\n",
    "    yy = np.arange(shape[1]) - shape[1]/2.+0.5\n",
    "    \n",
    "    r = np.sqrt((xx[:, None]-x0)**2 + (yy[None, :]-y0)**2)\n",
    "    psf = np.exp(-r**2./2./(sigmaPSF**2.)) / (2*math.pi*sigmaPSF)\n",
    "    return psf\n",
    "\n",
    "fig = plt.figure(figsize=(12,18))\n",
    "\n",
    "# uniform flux\n",
    "image = np.zeros((xdim, ydim))\n",
    "image[7,7] = Atrue\n",
    "plotCutout(image, loc=321, fig=fig, title=\"Truth\")\n",
    "\n",
    "# random Poisson process\n",
    "image = np.zeros((xdim, ydim))\n",
    "image[7,7] = np.random.poisson(Atrue)\n",
    "plotCutout(image, loc=322, fig=fig, title=\"Perfect detector, no atmosphere\")\n",
    "\n",
    "# PSF \n",
    "image = np.zeros((xdim, ydim))\n",
    "image = Atrue * makePSF(image.shape, 0, 0, sigmaPSF)\n",
    "plotCutout(image, loc=323, fig=fig, title=\"Now with atmosphere\")\n",
    "\n",
    "# PSF with background\n",
    "image += skyBg\n",
    "plotCutout(image, loc=324, fig=fig, title=\"Now with atmosphere and background\")\n",
    "\n",
    "# PSF with background and noise\n",
    "image = np.random.poisson(image)\n",
    "plotCutout(image, loc=325, fig=fig, title=\"W/ Atmosphere,background and noise\")\n",
    "\n",
    "simulatedImage = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Photometry (measuring the flux)\n",
    "\n",
    "We now have an image that we observe, and some ***understanding of the processes that created it***.\n",
    "We have encoded that understanding into a model.\n",
    "This means you can now use maximum likelihood to estimate the parameters of the underlying source - like the total area under the profile - a measurement of how much light we received from the source, or it's `FLUX`\n",
    "\n",
    "The `MAG_PSF` you plotted from the SDSS HLC files last week is directly related to the flux by $-2.5*log_{10}(\\text{Flux}) + \\text{Constant}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PSF Photometry: A Maximum Likelihood estimation of the flux\n",
    "\n",
    "So our **model** for the image is that it consists of a Gaussian with a flux normalization fo $A$ , plus the background (which we've removed), plus the Gaussian noise (caused by photon quantization).\n",
    "\n",
    "So, <u>**once the background is removed**</u>, for ***each pixel*** I can write:\n",
    "\n",
    ">$ I(x,y) = A * PSF(x - x_0, y - y_0) + r_i $\n",
    "\n",
    "where $A$ is the flux of the star (i.e. the thing we want), and $r_i$ is drawn from a Gaussian with\n",
    "\n",
    ">$N(0, \\sigma_{x,y} = \\sqrt{I_{x,y} + B})$\n",
    "\n",
    "and $B$ is the sky background. It's critical not to forget the background when computing the sigma -- for faint sources, this is where most of the measurement uncertainty comes from!\n",
    "\n",
    "### For a single pixel \n",
    "\n",
    "### $$\n",
    "\\begin{align}\n",
    "p(I(x_i, y_i)|A, PSF(x_i-x_0, y_i-y_0), \\sigma) &= N(I(x_i, y_i) - A*PSF(x_0, y_0)|\\sigma) \\\\\n",
    "& = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} A\\exp \\left( - \\frac{(I(x_i, y_i) - A*PSF(x_0, y_0))^2}{2 \\sigma^2} \\right) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### For a whole image then $p1 \\times p2 \\times p3$....\n",
    "\n",
    "### $$ \n",
    "\\begin{align}\n",
    "P &= \\Gamma p(I(x, y)|A, PSF(x_i-x_0, y_i-y_0), \\sigma) \\\\\n",
    "& = N(I(x_i, y_i) - A*PSF(x_0, y_0)|\\sigma) \\\\\n",
    "& = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} A\\exp \\left( - \\frac{(I(x_i, y_i) - A*PSF(x_0, y_0))^2}{2 \\sigma^2} \\right) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note this is practically identical to our case with fitting a line, except that instead of having one index $i$, we have two indices for the data points, $(x, y)$. And ***each pixel*** is an independent data point that constrains our model.\n",
    "\n",
    "So we can readily write out the log-likelihood as:\n",
    "\n",
    "### $$\\ln{L} = \\text{constant} - \\sum_{i=1}^N \\frac{\\left(I(x_i,y_i) - A\\  \\mathrm{PSF}(x_0,y_0)\\right)^2}{2 \\sigma^2}$$\n",
    "\n",
    "As we've seen , maximizing the likelihood of a product of normal distribution reduces to minimizing the $\\chi^2$, which is what you'll do next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.1 Assume the noise is constant, and minimize the log-likelihood analytically. \n",
    "(i.e. some calculus required)\n",
    "\n",
    "You may wish to define these quantities:\n",
    "\n",
    ">$\\phi_{x,y} = \\frac{1}{\\sigma^2} \\sum_{x,y} I_{x,y}\\cdot PSF_{x,y,\\sigma_{PSF}}$\n",
    "                             \n",
    ">$\\psi_{x,y} = \\frac{1}{\\sigma^2} \\sum_{x,y} PSF_{x,y,\\sigma_{PSF}}^2$\n",
    "\n",
    "\n",
    "Looking at the form of $\\phi_{x,y}$ and considering it for each pixel **what does it represent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR ANSWER HERE\n",
    "\n",
    "You can format equations in markdown - there's plenty of examples in this notebook itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q2.2 Estimating the true flux\n",
    "\n",
    "To estimate the true flux, we need to maximize the likelihood. That is equivalent to minimizing the $\\chi^2$. \n",
    "\n",
    "* estimate the background in the image\n",
    "* estimate the noise in our measurements (remember it's a Poisson process!)\n",
    "* as with the straight line estimate the true flux grid of A\n",
    "* Destermine the chi-sq/DoF at each location on the A grid and plot it\n",
    "* Compare the numerical estimate with your analytical estimate that you made with your answer to Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models with more parameters\n",
    "\n",
    "The iterative example above is a bit contrived as we can, and did, solve the MLE analytically \n",
    "\n",
    "It has the benefit of being general, however. We can apply the same technique to models with more parameters (within the limits of computing power available to us!). The other parameters could be the position of the object ($x$, $y$), or some measure of the shape of the object.\n",
    "\n",
    "As the number of parameters increases, the likelihood curve from the previous slide becomes the ***likelihood (hyper)surface***. The more dimensions there are, the more difficult (computationally expensive) it becomes to find its maximum using brute force solutions; even for 2D cases, we're likely to resort to ***minimization algorithms*** (e.g., Levenbergâ€“Marquardt or others)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q3: Measuring the size and brightness of a spherical, gaussian, galaxy\n",
    "\n",
    "In Homework 1, you had `MAG_PSF` not just for stars, but also for galaxies. \n",
    "\n",
    "Even in the ideal (space) case, the Galaxy will not be a point source. We'll imagine we're dealing with a \"Gaussian spherical galaxy\" -- i.e., one whose intensity  falls of as a 2D gaussian would. As with the star, we'll asume the position of the galaxy is known.\n",
    "\n",
    "Our model has two parameters: the measure of the extendedness of the galaxy -- $\\sigma$ -- and its total flux, $C$:\n",
    "\n",
    ">$ I(x, y) = \\frac{C}{2 \\pi \\sigma^2} \\exp \\left( -\\frac{(x-x_0)^2 + (y-y_0)^2}{2\\sigma^2} \\right) $\n",
    "\n",
    "We will now have to explore the likelihood surface in $(C, \\sigma)$ space, and find the point of its maximum.\n",
    "\n",
    "Note #2: When generating the simulated image, $I(x, y)$ needs to be ***convolved*** with the PSF. Fortunately (actually, because I'm lazy) we've chosen the galaxy profile to be gaussian, and the convolution of two gaussians with variances $\\sigma_1^2$ and $\\sigma_2^2$ is also a gaussian with the variance $\\sigma_1^2 + \\sigma_2^2$ (i.e., it's wider). \n",
    "\n",
    "Our function `gauss2D` utilizes this fact to generate the convolved image of the galaxy.\n",
    "\n",
    "* we will generate two cases with `gauss2D` below:\n",
    "* using this image as your data evaluate the log-likelihood\n",
    "    * in Q2, we only did this for the flux $A$\n",
    "    * now you have two parameters $C$ and it's shape $\\sigma$\n",
    "    * evaluate the likelihood on this grid \n",
    "    \n",
    "    `C = np.linspace(500, 1500, 101)`\n",
    "    \n",
    "    `Sigma = np.linspace(0, 2.5, 101)`\n",
    "    \n",
    "* plot the noiseless image and the PSF image, returned by `simulate`, `image` itself, and the difference between image and PSF image (also returned by simulate), and your estimated log-likehood surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss2D(muX, muY, sig, A, skyBg, sigPSF, Xpixels, Ypixels):\n",
    "    \"\"\"\n",
    "    Generate an image of size (Xpixels, Ypixels) with\n",
    "    a 2D circular Gaussian of total flux A\n",
    "    with standard deviation sigma^2=sig^2 + sigPSF^2\n",
    "    superimposed on a uniform background B and centered\n",
    "    on (muX, muY).\n",
    "    \"\"\"\n",
    "    r = np.sqrt((Xpixels-muX)**2 + (Ypixels-muY)**2)\n",
    "    # make and set image to the background value\n",
    "    image = np.empty(r.shape)\n",
    "    image.fill(skyBg)\n",
    "\n",
    "    ## now add circular gaussian profile (normalized to A)\n",
    "    # source gauss convolved with single-gauss PSF  \n",
    "    sigConvSquare = sig**2 + sigPSF**2\n",
    "    image += A*np.exp(-r**2/2/sigConvSquare) / (2*math.pi*sigConvSquare)\n",
    "    return image\n",
    "\n",
    "\n",
    "def addnoise(inimage, sigNoise, sourceImage, addsourcenoise=0): \n",
    "    \"\"\"Add gaussian noise to the image, and return the image and variance plane\"\"\"\n",
    "    image = np.copy(inimage)\n",
    "    image += np.random.normal(0, sigNoise, image.shape)\n",
    "    variance = 0*image + sigNoise**2\n",
    "\n",
    "    if (addsourcenoise):\n",
    "        gain = 1.0  # as a reminder...\n",
    "        sourceVariance = sourceImage/gain\n",
    "        image += np.random.normal(0, np.sqrt(sourceVariance), image.shape)\n",
    "        variance += sourceVariance\n",
    "\n",
    "    return image, variance \n",
    "\n",
    "\n",
    "def simulate(muXtrue, muYtrue, sigtrue, Atrue, skyBg, sigmaPSF, sigmaNoise):\n",
    "    # set seed\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # define the (square) grid\n",
    "    xpix = np.linspace(-7, 7, 15)\n",
    "\n",
    "    ## make psf (sigtrue=0) \n",
    "    psf = gauss2D(muXtrue, muYtrue, 0, Atrue, skyBg, sigmaPSF, xpix[:, np.newaxis], xpix)\n",
    "\n",
    "    ## make noiseless image (convolved with psf given by sigmaPSF, image size given by 1Dpixels) \n",
    "    nonoise = gauss2D(muXtrue, muYtrue, sigtrue, Atrue, skyBg, sigmaPSF, xpix[:, np.newaxis], xpix)\n",
    " \n",
    "    ## now add noise\n",
    "    image, variance = addnoise(nonoise, sigmaNoise, 0) \n",
    "\n",
    "    ## difference object - psf\n",
    "    diffimage = image - psf\n",
    "\n",
    "    return nonoise, psf, image, diffimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case 1 - a sanity check - if sigtrue (i.e. the shape of the galaxy) is 0 we're back to dealing with a single star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muXtrue = 0.0     # source x centroid \n",
    "muYtrue = 0.0     # source y centroid \n",
    "sigtrue = 0.0     # the intrinsic gaussian source width, sigma (in pixels) \n",
    "Atrue = 1000.0    # the source count normalization\n",
    "skyBg = 25        # sky background\n",
    "sigmaPSF = 1.5    # in pixels, corresponds to seeing = 1.5*0.2*2.355 = 0.7 arcsec for LSST (0.2\" pix)\n",
    "sigmaNoise = 5.0  # gaussian sigma for white noise (counts), e.g. due to sky \n",
    "\n",
    "\n",
    "nonoise, psf, image, diffimage = simulate(muXtrue, muYtrue, sigtrue, Atrue, skyBg, sigmaPSF, sigmaNoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE TO SOLVE THE HOMEWORK GOES HERE - TRY TO MAKE A FUNCTION YOU CAN REUSE FOR CASE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case 2 - if sigtrue is non-zero, we're dealing with a spherical cow galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "muXtrue = 0.0     # source x centroid \n",
    "muYtrue = 0.0     # source y centroid \n",
    "sigtrue = 1.0     # the intrinsic gaussian source width, sigma (in pixels) \n",
    "Atrue = 1000.0    # the source count normalization\n",
    "skyBg = 25        # sky background\n",
    "sigmaPSF = 1.5    # in pixels, corresponds to seeing = 1.5*0.2*2.355 = 0.7 arcsec for LSST (0.2\" pix)\n",
    "sigmaNoise = 5.0  # gaussian sigma for white noise (counts), e.g. due to sky \n",
    "\n",
    "nonoise, psf, image, diffimage = simulate(muXtrue, muYtrue, sigtrue, Atrue, skyBg, sigmaPSF, sigmaNoise)\n",
    "\n",
    "# IF YOU WROTE A SENSIBLE FUNCTION FOR THE STAR CASE, YOU CAN JUST REUSE IT HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every one of the measurements in the SDSS HLC files was estimated using a more sophisticated version of this process."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:fds] *",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
