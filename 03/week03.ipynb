{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 1920, 'height': 1080, 'scroll': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 03, ASTR 596: Fundamentals of Data Science\n",
    "\n",
    "### MLE, Uncertainty, and Philosophy\n",
    "\n",
    "### Gautham Narayan \n",
    "##### <gsn@illinois.edu>\n",
    "\n",
    "\n",
    "##### With contributions totally ripped of from Zjelko Ivezic and Mario Juric (UW),  Federica Bianco (U. Del), Phil Marshall and Adam Mantz (SLAC), Kaisey Mandel (Cambridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Quick review of Homework 1 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "* Describing random variables\n",
    "    * null hypothesis rejection testing\n",
    "    * outlier rejection with $\\sigma$-clipping and robust statistics\n",
    "* M-estimators and maximum likelihood\n",
    "    * HW includes using Huber loss as a robust M-estimator\n",
    "* the Fisher matrix to get model uncertainties and the Cramer-Rao bound\n",
    "* Goodness of fit\n",
    "\n",
    "\n",
    "# <center> It's fine if the last two items seem vague - we've got all this week on maximum likelihood! </center>\n",
    "\n",
    "### <center> Other things we should talk more about? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review:\n",
    "\n",
    "With both the method of moments, and robust statistics:\n",
    "* we asserted the data followed some underlying distribution - a **model** for the data\n",
    "* and then estimated the parameters of that model with sample moments/ robust L-estimators  \n",
    "   * this let us do *Null Hypotheses Rejection Testing (NHRT)*\n",
    "   \n",
    "This is a critical step for us because:\n",
    "* theories should be **falsifiable**\n",
    "* analysis should be **reproducible** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Review:\n",
    "\n",
    "* With M-estimators, you defined a loss function\n",
    "    * loss functions are functions of the quantity you are trying to estimate from the data\n",
    "    * these have to be chosen to have \"nice\" properties \n",
    "    * there is no ONE TRUE ANSWER i.e. model choice depends on what you are trying to learn from the data\n",
    "    * you minimize the loss and the location of the minimum gives you the value of estimator\n",
    "* Directly related to maximum likelihood estimation (MLE) \n",
    "    * minimizing the loss = maximizing the likelihood\n",
    "    * you've seen this with the sum of squared residuals\n",
    "    * - Log-likelihood, $\\chi^2$ and goodness of fit\n",
    "* This framework also allows you to get some notion of uncertainty\n",
    "    * Fisher matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"nhrt_key.png\"> \n",
    "Courtesy Federica Bianco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But there are some natural questions that arise:\n",
    "\n",
    "* How do you know you specified the right model if you can't rule it out with the observations?\n",
    "* How do you know you had enough data to estimate the parameters of the model robustly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Big Picture: What Are We After?\n",
    "\n",
    "There are two fundamental types of statistical questions we want to answer:\n",
    "\n",
    "#### 1. Model Selection\n",
    "\n",
    "*Given two potential Models, which better describes my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Is there a linear trend in this data?\n",
    "- Does a linear or quadratic fit describe our data better?\n",
    "- Is there a periodic signal in this timeseries?\n",
    "- Does this star have a planet around it? Does this star have two planets around it?\n",
    "\n",
    "Often one of the two models is a *null hypothesis*, or a baseline model in which the effect you're interested in is not observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. Model Fitting\n",
    "*Given this Model, what parameters best fit my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- What are the slope and intercept of a line of best-fit?\n",
    "- What are the parameters of the best quadratic fit?\n",
    "- What is the frequency, amplitude, and phase of a sinusoidal fit?\n",
    "- What are the orbital parameters of a planet in this radial velocity data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simply, how confident are you in your model itself?\n",
    "\n",
    "#### This is on the surface a straightforward question, but it leads to a deep philosophical split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Frequentism\n",
    "\n",
    "In this view of the Universe, there is some underlying truth.\n",
    "\n",
    "I we the photon flux F from a given star, then measure it again, then again, and so on, each time I will get a slightly different answer due to the statistical error of my measuring device.\n",
    "\n",
    "In the limit of a large number of measurements, the frequency of any given value indicates the probability of measuring that value.\n",
    "\n",
    "For *frequentists* probabilities are fundamentally related to frequencies of events i.e. **$P(D|H)$**.\n",
    "\n",
    "This means, for example, that in a strict frequentist view, it is meaningless to talk about the probability of the true flux of the star: the true flux is (by definition) a single fixed value. \n",
    "\n",
    "To talk about a frequency distribution for a fixed value or model parameter is nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"left\" src=\"41114_2018_17_Fig4_HTML.png\" width=\"400px\">\n",
    "\n",
    "### Let's look at an actual example from the literature\n",
    "\n",
    "Fig 4: These plots illustrate the differences between $\\Lambda$CDM and Galileon models (see Sect. 7.3.1), with (**GN: Solid lines**) and without massive neutrinos (**GN: Dashed lines**). The Galileon models have background Friedmann equations that contain a scalar-field energy density contribution that generates late time cosmic acceleration and has an evolution consistent with observations and thus similar to that of a $\\Lambda$CDM model.\n",
    "\n",
    "The Top: CMB temperature power spectra showing the ISW effect at low multipoles. \n",
    "\n",
    "Middle: CMB lensing potential spectra. Bottom: linear matter power spectra. The models plotted in dashed lines indicate **their best fit models to Ade et al. (2014c) temperature data, WMAP9 polarization data (Hinshaw et al. 2013), and Planck-2013 CMB lensing (Ade et al. 2014d).** \n",
    "\n",
    "https://link.springer.com/article/10.1007/s41114-018-0017-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The thing to note here is that there is a model that has been \"fit\" to some noisy data, but the model is taken as \"Truth.\" \n",
    "\n",
    "# There is no uncertainty reported about the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Bayesian View\n",
    "\n",
    "For Bayesians, the concept of probability is extended to cover degrees of certainty about statements. \n",
    "\n",
    "Say a Bayesian claims to measure the flux F of a star with some probability P(F): that probability can certainly be estimated from frequencies in the limit of a large number of repeated experiments, but this is not fundamental. \n",
    "\n",
    "The probability is a statement of my knowledge of what the measurement result will be. \n",
    "\n",
    "For Bayesians, probabilities are fundamentally related to our own knowledge about an event. \n",
    "\n",
    "This means, for example, that in a Bayesian view, we can meaningfully talk about the probability that the true flux of a star lies in a given range. \n",
    "\n",
    "That probability codifies our knowledge of the value based on prior information and/or available data i.e. **$P(H|D)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For more a more fleshed-out discussion of these different definitions and their consequences, you can see Jake VanderPlas' [series of blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two quantities, $P(H|D)$ and $P(D|H)$ are related to each other by Bayes' rule:\n",
    "\n",
    "# $$ P(H|D) \\propto P(D|H) \\cdot P(H) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Wherefore the Controversy?\n",
    "\n",
    "When we write Bayes' rule this way, we're all of a sudden doing something controversial: can you see where this controversy lies?\n",
    "\n",
    "Two controversial points:\n",
    "\n",
    "- We have a probability distribution over model parameters. A frequentist would say this is meaningless!\n",
    "\n",
    "- The answer depends on the prior $P(H)$. This is the probability of the model without any data: how are we supposed to know that?\n",
    "\n",
    "Nevertheless, applying Bayes' rule in this manner gives us a means of quantifying our knowledge of the parameters $\\theta$ of some hypothesis $H$ given observed data $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the Point?\n",
    "\n",
    "At first blush, this might all seem needlessly complicated. Why not simply maximize the likelihood and be done with it? Why multiply by a prior at all?\n",
    "\n",
    "There are a couple good reasons to go through all of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### \"Purity\"\n",
    "\n",
    "Many advocates of the Bayesian approach argue for it's philosophical purity: you quantify knowledge in terms of a probability, then follow the math to compute the answer.\n",
    "\n",
    "The fact that you need to specify a prior might be inconvenient, but we can't simply pretend it away.\n",
    "\n",
    "There are good reasons to think that the Bayesian posterior is just the quantity we wish to compute; in that case we should compute it, however inconvenient.\n",
    "\n",
    "Perhaps the most vocal 20th century proponent of this view was Jaynes; I'd highly suggest looking at his book, *Probability Theory: The Logic of Science* ([PDF here](http://bayes.wustl.edu/etj/prob/book.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter Uncertainties\n",
    "\n",
    "Whether frequentist or Bayesian, the maximum likelihood \"point estimate\" is only a small part of the picture. What we're really interested in scientifically is the *uncertainty* of the estimates. So simply reporting a point estimate is not appropriate.\n",
    "\n",
    "In frequentist approaches, \"error bars\" are generally computed from *Confidence Intervals*, which effectively measure $P(\\hat\\theta\\mid\\theta)$, rather than $P(\\theta\\mid D)$.\n",
    "It takes some mental gymnastics to relate the confidence interval to the quantity we as scientists have in mind when we say \"uncertainty\".\n",
    "\n",
    "In the Bayesian approach, we are actually measuring $P(\\theta\\mid D)$ from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For some approachable reading on frequentist vs. Bayesian uncertainties, I'd suggest [The Fallacy of Placing Confidence in Confidence Intervals](http://learnbayes.org/papers/confidenceIntervalsFallacy/), as well as Jake's (rather opinionated) blog post on the topic, [Confidence, Credibility, and why Frequentism and Science do not Mix](http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside - the denominator in Bayes' rule\n",
    "\n",
    "\n",
    "The denominator in Bayes' rule is the Evidence $P(D)$\n",
    "\n",
    "# $$ P(H|D) = \\frac{P(D|H) \\cdot P(H)}{P(D)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider that the evidence can be expressed as an integral using the identities we covered above:\n",
    "$$\n",
    "P(D) = \\int P(D\\mid\\theta) P(\\theta) d\\theta\n",
    "$$\n",
    "\n",
    "In other words, it is the integral over the likelihood for *all possible values of theta*.\n",
    "\n",
    "This means we could have called the Fully Marginalized Likelihood (FML) instead of the evidence. \n",
    "\n",
    "When your likelihood is a complicated function of many parameters, computing this integral can become extremely costly (a manifestation of the *curse of dimensionality*), which makes the acronym doubly appropriate in any situation where you actually need it.\n",
    "\n",
    "\n",
    "In general, for **model fitting**, you can ignore the FML as a simple normalization term. In **model selection**, the FML can become important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving beyond this controversy requires at least one thing:\n",
    "\n",
    "If you have a \"flat\" or uniformative prior:\n",
    "\n",
    "$$ P(H) = 1$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$ P(H|D) \\propto P(D|H) $$\n",
    "\n",
    "\n",
    "But you already know that $P(D|H)$ is just the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The liklihood function then has to play a dual role:\n",
    "    \n",
    "Given a fixed set of model parameters ($\\theta = \\theta_0$) it is evaluating how likely the data you observed is.\n",
    "\n",
    "\n",
    "But, you can also consider the likelihood to be a function of the model parameters, given fixed data - we did this last week, deriving the MLE estimate for a homoscedastic Gaussian $N(\\mu,\\sigma)$.\n",
    "\n",
    "You cast the likelihood as a function you evaluated at a range of model parameter values.\n",
    "\n",
    "You'll also have to do this on your homework, except now you've got more than 1 parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval vs. Credible Region\n",
    "\n",
    "Even with a flat uniform prior, the two approaches **are not the same.**\n",
    "\n",
    "In the **frequentist paradigm**, the meaning of the *confidence interval* $\\mu_0 \\pm \\sigma_{\\mu}$ is \n",
    "the interval that would contain the true $\\mu$ (from which the data were drawn) in 68% cases\n",
    "of a large number of imaginary repeated experiments (each with a different N values of $\\{x_i\\}$). \n",
    "\n",
    "The same interval follows from the **Bayesian approach** with uniform priors.\n",
    "However, the meaning of that so-called *credible region* is *fundamentally different*: it is the interval\n",
    "that contains the true $\\mu$ with a probability of 68%, given the given dataset (our dear one and only \n",
    "dataset - there are no imaginary experiments in Bayesian paradigm). \n",
    "\n",
    "This credible region is the relevant quantity in the context of scientific measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Essence of the Bayesian Method \n",
    "\n",
    "The basic premise of the Bayesian method is that probability statements are not limited to data, \n",
    "but can be made for model parameters and models themselves. Inferences are made by producing \n",
    "probability density functions (pdfs); most notably, **model parameters are treated as random variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercise:\n",
    "\n",
    "Seeing the drawback of an MLE approach, when you fail to incorporate prior information is easy.\n",
    "\n",
    "Let's do it with some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.09934283 0.97234714 1.12953771]\n"
     ]
    }
   ],
   "source": [
    "### Let's draw a homoscedastic sample of {x_i} from a Gaussian and see what happens with L\n",
    "# first generate a sample of N points drawn from N(mu,sigma):\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "sampleSize=3\n",
    "mu = 1.0\n",
    "sigma = 0.2 \n",
    "sample = st.norm(mu, sigma).rvs(sampleSize) \n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute likelihoods for each point using true mu \n",
    "muGrid = np.linspace(0,2,1000)\n",
    "L1 = st.norm(sample[0], sigma).pdf(muGrid) \n",
    "L2 = st.norm(sample[1], sigma).pdf(muGrid) \n",
    "L3 = st.norm(sample[2], sigma).pdf(muGrid) \n",
    "\n",
    "# what's the total likelihood and where is the maximum likelihood\n",
    "\n",
    "\n",
    "# plot each of L1, L2, L3 and the total likelihood as a function of mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what happens if I tell you that mu>0.9?\n",
    "# adjust L1, L2, L3 to reflect this and recompute the total likelihood and maximum likelihood"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:fds] *",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
